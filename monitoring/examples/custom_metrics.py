"""
Exemplo de como adicionar m√©tricas customizadas Prometheus na aplica√ß√£o.

Este arquivo demonstra como integrar m√©tricas customizadas do Prometheus
no c√≥digo Python do DealHunter Pro.
"""

from prometheus_client import Counter, Histogram, Gauge, start_http_server
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST
from http.server import HTTPServer, BaseHTTPRequestHandler
import time

# ============================================================================
# M√âTRICAS CUSTOMIZADAS
# ============================================================================

# Contador de jobs processados por tipo e status
jobs_processed_total = Counter(
    'dealhunter_jobs_processed_total',
    'Total de jobs processados pela aplica√ß√£o',
    ['job_type', 'status']  # Labels: tipo de job e status (success/failed)
)

# Histograma de dura√ß√£o de scraping
scraping_duration_seconds = Histogram(
    'dealhunter_scraping_duration_seconds',
    'Dura√ß√£o do processo de scraping em segundos',
    ['source'],  # Label: fonte (ml, affiliate_hub, etc)
    buckets=[1, 5, 10, 30, 60, 120, 300, 600]  # Buckets customizados
)

# Gauge de ofertas coletadas
offers_collected = Gauge(
    'dealhunter_offers_collected',
    'N√∫mero atual de ofertas coletadas',
    ['source', 'status']  # Labels: fonte e status (pending/processed)
)

# Contador de erros por tipo
errors_total = Counter(
    'dealhunter_errors_total',
    'Total de erros encontrados',
    ['error_type', 'component']  # Labels: tipo de erro e componente
)

# Histograma de tempo de enriquecimento
enrichment_duration_seconds = Histogram(
    'dealhunter_enrichment_duration_seconds',
    'Dura√ß√£o do processo de enriquecimento em segundos',
    ['offer_id'],
    buckets=[0.5, 1, 2, 5, 10, 30, 60]
)

# ============================================================================
# EXEMPLO DE USO
# ============================================================================

def example_scraping_metrics():
    """Exemplo de como usar m√©tricas durante scraping."""
    source = 'ml'
    start_time = time.time()
    
    try:
        # Simula scraping
        # ... seu c√≥digo de scraping aqui ...
        
        # Registra dura√ß√£o
        duration = time.time() - start_time
        scraping_duration_seconds.labels(source=source).observe(duration)
        
        # Incrementa contador de sucesso
        jobs_processed_total.labels(job_type='scraping', status='success').inc()
        
        # Atualiza gauge de ofertas coletadas
        offers_collected.labels(source=source, status='pending').set(150)
        
    except Exception as e:
        # Incrementa contador de falha
        jobs_processed_total.labels(job_type='scraping', status='failed').inc()
        
        # Registra erro
        errors_total.labels(error_type=type(e).__name__, component='scraper').inc()
        raise


def example_enrichment_metrics(offer_id: str):
    """Exemplo de como usar m√©tricas durante enriquecimento."""
    start_time = time.time()
    
    try:
        # Simula enriquecimento
        # ... seu c√≥digo de enriquecimento aqui ...
        
        # Registra dura√ß√£o
        duration = time.time() - start_time
        enrichment_duration_seconds.labels(offer_id=offer_id).observe(duration)
        
        # Incrementa contador de sucesso
        jobs_processed_total.labels(job_type='enrichment', status='success').inc()
        
        # Atualiza gauge
        offers_collected.labels(source='ml', status='processed').inc()
        
    except Exception as e:
        # Incrementa contador de falha
        jobs_processed_total.labels(job_type='enrichment', status='failed').inc()
        
        # Registra erro
        errors_total.labels(error_type=type(e).__name__, component='enricher').inc()
        raise


# ============================================================================
# HEALTH CHECK ENDPOINT
# ============================================================================

class MetricsHandler(BaseHTTPRequestHandler):
    """Handler HTTP para expor m√©tricas Prometheus."""
    
    def do_GET(self):
        if self.path == '/metrics':
            self.send_response(200)
            self.send_header('Content-Type', CONTENT_TYPE_LATEST)
            self.end_headers()
            self.wfile.write(generate_latest())
        elif self.path == '/health':
            self.send_response(200)
            self.send_header('Content-Type', 'application/json')
            self.end_headers()
            self.wfile.write(b'{"status": "healthy"}')
        else:
            self.send_response(404)
            self.end_headers()
    
    def log_message(self, format, *args):
        # Suprime logs do servidor HTTP
        pass


def start_metrics_server(port: int = 8000):
    """
    Inicia servidor HTTP para expor m√©tricas Prometheus.
    
    Args:
        port: Porta onde o servidor ser√° iniciado (padr√£o: 8000)
    """
    server = HTTPServer(('0.0.0.0', port), MetricsHandler)
    print(f"üìä Servidor de m√©tricas iniciado em http://localhost:{port}/metrics")
    print(f"üè• Health check dispon√≠vel em http://localhost:{port}/health")
    server.serve_forever()


# ============================================================================
# INTEGRA√á√ÉO COM ASYNCIO
# ============================================================================

import asyncio
from threading import Thread


def start_metrics_server_thread(port: int = 8000):
    """
    Inicia servidor de m√©tricas em thread separada (compat√≠vel com asyncio).
    
    Args:
        port: Porta onde o servidor ser√° iniciado
    """
    def run_server():
        start_metrics_server(port)
    
    thread = Thread(target=run_server, daemon=True)
    thread.start()
    return thread


# ============================================================================
# EXEMPLO DE INTEGRA√á√ÉO NO C√ìDIGO EXISTENTE
# ============================================================================

# No seu main.py ou onde inicia a aplica√ß√£o:
"""
from monitoring.examples.custom_metrics import (
    start_metrics_server_thread,
    jobs_processed_total,
    scraping_duration_seconds,
    offers_collected
)

# Inicia servidor de m√©tricas
start_metrics_server_thread(port=8000)

# Use as m√©tricas no seu c√≥digo:
jobs_processed_total.labels(job_type='scraping', status='success').inc()
"""
